{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9byRZ7DNqBE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_mmdet.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5ShQixcNqBI"
      },
      "source": [
        "## 0. Preperation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a887_S0QNqBJ"
      },
      "source": [
        "- Install latest version of SAHI and MMDetection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X7Jqdj8NqBK",
        "outputId": "ad23415a-3205-42ec-a5c2-fb1e6223869e"
      },
      "outputs": [],
      "source": [
        "%pip install Pillow==9.0.0\n",
        "%pip install -U sahi mmcv==1.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y0ogTY-9NqBL",
        "outputId": "6f0341dc-e6f6-4432-b235-90128c8ed21b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2VZiZcaNqBM"
      },
      "source": [
        "- Import required modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-kLagIIapAs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q4aXEk-SNqBM"
      },
      "outputs": [],
      "source": [
        "# arrange an instance segmentation model for test\n",
        "from sahi.utils.mmdet import (\n",
        "    download_mmdet_cascade_mask_rcnn_model,\n",
        "    download_mmdet_config,\n",
        ")\n",
        "\n",
        "# import required functions, classes\n",
        "from sahi.model import MmdetDetectionModel\n",
        "from sahi.utils.cv import read_image\n",
        "from sahi.utils.file import download_from_url\n",
        "from sahi.predict import get_prediction, get_sliced_prediction, predict, predict_fiftyone\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S62ySEnkNqBN"
      },
      "source": [
        "- Download a cascade mask rcnn model and two test images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3GI5uWyeNqBO"
      },
      "outputs": [],
      "source": [
        "# download cascade mask rcnn model&config\n",
        "model_path = '../latest.pth'\n",
        "download_mmdet_cascade_mask_rcnn_model(model_path)\n",
        "# config_path = download_mmdet_config(model_name=\"cascade_rcnn\", config_file_name=\"cascade_mask_rcnn_r50_fpn_1x_coco.py\",)\n",
        "config_path = '../finetune.py'\n",
        "\n",
        "# download test images into demo_data folder\n",
        "download_from_url('https://raw.githubusercontent.com/obss/sahi/main/demo/demo_data/small-vehicles1.jpeg', 'demo_data/small-vehicles1.jpeg')\n",
        "download_from_url('https://raw.githubusercontent.com/obss/sahi/main/demo/demo_data/terrain2.png', 'demo_data/terrain2.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzM6o04iNqBP"
      },
      "source": [
        "## 1. Standard Inference with a MMDetection Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwTBlHOmNqBQ"
      },
      "source": [
        "- Instantiate a detection model by defining model weight path, confing path and other parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_s4UPKrNqBQ",
        "outputId": "eeb0d98a-9502-43dd-d582-341112e3bd04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load checkpoint from local path: ../latest.pth\n"
          ]
        }
      ],
      "source": [
        "detection_model = MmdetDetectionModel(\n",
        "    model_path=model_path,\n",
        "    config_path=config_path,\n",
        "    confidence_threshold=0.4,\n",
        "    device=\"cuda:0\", # or 'cuda:0'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T17O8LErNqBR"
      },
      "source": [
        "- Perform prediction by feeding the get_prediction function with an image path and a DetectionModel instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dgo5ViINqBR"
      },
      "outputs": [],
      "source": [
        "result = get_prediction(\"demo_data/small-vehicles1.jpeg\", detection_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ46PODpNqBR"
      },
      "source": [
        "- Or perform prediction by feeding the get_prediction function with a numpy image and a DetectionModel instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL9yNm5YNqBS"
      },
      "outputs": [],
      "source": [
        "result = get_prediction(read_image(\"demo_data/small-vehicles1.jpeg\"), detection_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apqrs420NqBS"
      },
      "source": [
        "- Visualize predicted bounding boxes and masks over the original image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "eR8ESGNMNqBS",
        "outputId": "082d757d-ca70-499d-eef3-590f93fddd9e"
      },
      "outputs": [],
      "source": [
        "result.export_visuals(export_dir=\"demo_data/\")\n",
        "\n",
        "Image(\"demo_data/prediction_visual.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHVAqlHmNqBT"
      },
      "source": [
        "## 2. Sliced Inference with a MMDetection Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MVxYmPsNqBT"
      },
      "source": [
        "- To perform sliced prediction we need to specify slice parameters. In this example we will perform prediction over slices of 256x256 with an overlap ratio of 0.2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTNGSX8zNqBT",
        "outputId": "98828e04-8e6d-45d8-bd06-6ee89af9ef6a"
      },
      "outputs": [],
      "source": [
        "result = get_sliced_prediction(\n",
        "    \"demo_data/small-vehicles1.jpeg\",\n",
        "    detection_model,\n",
        "    slice_height = 256,\n",
        "    slice_width = 256,\n",
        "    overlap_height_ratio = 0.2,\n",
        "    overlap_width_ratio = 0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyIicALyNqBU"
      },
      "source": [
        "- Visualize predicted bounding boxes and masks over the original image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "d2aPR9iLNqBU",
        "outputId": "363b40ee-9c4e-4b17-e426-71dfbd4f2166"
      },
      "outputs": [],
      "source": [
        "result.export_visuals(export_dir=\"demo_data/\")\n",
        "\n",
        "Image(\"demo_data/prediction_visual.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch9AWFKqNqBV"
      },
      "source": [
        "## 3. Prediction Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8izq1fbNqBV"
      },
      "source": [
        "- Predictions are returned as [sahi.prediction.PredictionResult](sahi/prediction.py), you can access the object prediction list as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cldO8iJ3NqBV"
      },
      "outputs": [],
      "source": [
        "object_prediction_list = result.object_prediction_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9Cig2OgNqBV",
        "outputId": "f1d7bf48-36ed-48bd-a617-5f2fab011b79"
      },
      "outputs": [],
      "source": [
        "object_prediction_list[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRM7Te2gNqBV"
      },
      "source": [
        "- ObjectPrediction's can be converted to [COCO annotation](https://cocodataset.org/#format-data) format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtyEoz1mNqBV",
        "outputId": "3e1f4380-9973-4d89-ae85-ec67a318caaf"
      },
      "outputs": [],
      "source": [
        "result.to_coco_annotations()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l29FUy3KNqBW"
      },
      "source": [
        "- ObjectPrediction's can be converted to [COCO prediction](https://github.com/i008/COCO-dataset-explorer) format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSV4Kk3ENqBW",
        "outputId": "d5e98646-d5a2-44ae-b84b-588e822b3b7b"
      },
      "outputs": [],
      "source": [
        "result.to_coco_predictions(image_id=1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J0GMkoJNqBW"
      },
      "source": [
        "- ObjectPrediction's can be converted to [imantics](https://github.com/jsbroks/imantics) annotation format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ga6htLtcqHF",
        "outputId": "91d903c6-35c2-4f17-a7fb-e2ecee73838b"
      },
      "outputs": [],
      "source": [
        "%pip install -U imantics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IABLIIvZNqBW",
        "outputId": "8d405e3b-24f2-426b-da91-ea563f701824"
      },
      "outputs": [],
      "source": [
        "result.to_imantics_annotations()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs_kBdHjNqBW"
      },
      "source": [
        "- ObjectPrediction's can be converted to [fiftyone](https://github.com/voxel51/fiftyone) detection format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFgfUZmzcyRF"
      },
      "outputs": [],
      "source": [
        "%pip install -U fiftyone[desktop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGY6pMoF-Ojx"
      },
      "outputs": [],
      "source": [
        "%pip install ipywidgets>=7.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkPodytNNqBW",
        "outputId": "8299d7c2-014b-42da-b630-ddf2082fcb18"
      },
      "outputs": [],
      "source": [
        "result.to_fiftyone_detections()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sNN1x8xS23jH",
        "outputId": "5cb4036d-e884-4b6c-f0aa-20654f10e1fe"
      },
      "outputs": [],
      "source": [
        "# import fiftyone as fo\n",
        "# dataset = fo.Dataset()\n",
        "# dataset.add_sample(fo.Sample(filepath='demo_data/small-vehicles1.jpeg'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "4sbJhUk-8_sG",
        "outputId": "a9837908-0738-49d6-eb1b-ffedd4782040"
      },
      "outputs": [],
      "source": [
        "# with fo.ProgressBar() as pb:\n",
        "#   for sample in pb(dataset):\n",
        "#     detections = []\n",
        "#     for d in result.to_fiftyone_detections():\n",
        "#       detections.append(d)\n",
        "#     sample['ssdlite-mobilenetv2'] = fo.Detections(detections=detections)\n",
        "#     sample.save()\n",
        "\n",
        "# session = fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfasGxdiNqBW"
      },
      "source": [
        "## 4. Batch Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCYq4rBSNqBX"
      },
      "source": [
        "- Set model and directory parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Eg5eVjQ5NqBX"
      },
      "outputs": [],
      "source": [
        "model_type = \"mmdet\"\n",
        "model_path = model_path\n",
        "model_config_path = config_path\n",
        "model_device = \"cuda:0\" # or 'cuda:0'\n",
        "model_confidence_threshold = 0.4\n",
        "\n",
        "slice_height = 256\n",
        "slice_width = 256\n",
        "overlap_height_ratio = 0.2\n",
        "overlap_width_ratio = 0.2\n",
        "\n",
        "source_image_dir = \"./demo_data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiF8AJAcNqBX"
      },
      "source": [
        "- Perform sliced inference on given folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNOq6IIzNqBX",
        "outputId": "ce3ca1b2-c89a-4366-8675-a4439aa6b5f7"
      },
      "outputs": [],
      "source": [
        "# predict(\n",
        "#     model_type=model_type,\n",
        "#     model_path=model_path,\n",
        "#     model_config_path=config_path,\n",
        "#     model_device=model_device,\n",
        "#     model_confidence_threshold=model_confidence_threshold,\n",
        "#     source=source_image_dir,\n",
        "#     no_sliced_prediction=True\n",
        "#     # slice_height=slice_height,\n",
        "#     # slice_width=slice_width,\n",
        "#     # overlap_height_ratio=overlap_height_ratio,\n",
        "#     # overlap_width_ratio=overlap_width_ratio,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone as fo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = fo.Dataset()\n",
        "for i in os.listdir('./demo_data'):\n",
        "    dataset.add_sample(fo.Sample(filepath='demo_data/' + i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1% |/----------------|   2/191 [147.3ms elapsed, 13.9s remaining, 13.6 samples/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/anastasispk/Dev/mmdetection/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████████| 191/191 [11.5s elapsed, 0s remaining, 17.0 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "with fo.ProgressBar() as pb:\n",
        "        for sample in pb(dataset):\n",
        "            prediction_result = get_prediction(\n",
        "                    image=sample.filepath,\n",
        "                    detection_model=detection_model,\n",
        "                    shift_amount=[0, 0],\n",
        "                    full_shape=None,\n",
        "                    postprocess=None,\n",
        "                    verbose=0,\n",
        "                )\n",
        "            sample[model_type] = fo.Detections(detections=prediction_result.to_fiftyone_detections())\n",
        "            sample.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800\"\n",
              "            src=\"http://localhost:5151/?context=ipython&subscription=739013ec-6e2c-4ed8-9e1f-cfed6f4fec21\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fc16ccd8f10>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800\"\n",
              "            src=\"http://localhost:5151/?context=ipython&subscription=8604cf01-c833-478d-a7c6-ca12274b62a4\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fc1903a1eb0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "session = fo.launch_app()\n",
        "session.dataset = dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iP3c26n4NqBX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'validation' to '/home/anastasispk/fiftyone/coco-2017/validation' if necessary\n",
            "Downloading annotations to '/home/anastasispk/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
            " 100% |██████|    1.9Gb/1.9Gb [50.3s elapsed, 0s remaining, 37.1Mb/s]      \n",
            "Extracting annotations to '/home/anastasispk/fiftyone/coco-2017/raw/instances_val2017.json'\n",
            "Downloading 191 images\n",
            " 100% |██████████████████| 191/191 [47.8s elapsed, 0s remaining, 4.4 images/s]    \n",
            "Writing annotations for 191 downloaded samples to '/home/anastasispk/fiftyone/coco-2017/validation/labels.json'\n",
            "Dataset info written to '/home/anastasispk/fiftyone/coco-2017/info.json'\n",
            "Loading 'coco-2017' split 'validation'\n",
            " 100% |█████████████████| 191/191 [3.9s elapsed, 0s remaining, 53.3 samples/s]      \n",
            "Dataset 'coco-2017-validation' created\n"
          ]
        }
      ],
      "source": [
        "# import fiftyone.zoo as foz\n",
        "\n",
        "# # To download the COCO dataset for only the \"person\" and \"car\" classes\n",
        "# dataset = foz.load_zoo_dataset(\n",
        "#     \"coco-2017\",\n",
        "#     split=\"validation\",\n",
        "#     label_types=[\"detections\", \"segmentations\"],\n",
        "#     classes=[\"traffic light\"],\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "inference_for_mmdetection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('mmdetection')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2d540a93ef7f9ebe060f57d295e47f35d07d5aa0ae78463bc749f9dde03f2bc5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
